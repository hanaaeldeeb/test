{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 151,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "import sys\n",
                "from recommenders.datasets.python_splitters import python_chrono_split\n",
                "\n",
                "from recommenders.datasets import covid_utils\n",
                "from recommenders.models.tfidf.tfidf_utils import TfidfRecommender\n",
                "from recommenders.datasets import movielens\n",
                "# from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "import torch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "metadata": {},
            "outputs": [],
            "source": [
                "movies_df = pd.read_csv('/home/ee303/test/dataset/GENRES/ml-1m/movies.dat',\n",
                "                        delimiter='::', engine= 'python', header=None,\n",
                "                        names=['movie_name', 'genre'],encoding='latin1')\n",
                "#preprocess movie.csv file\n",
                "movies_df.reset_index(inplace=True)\n",
                "movies_df.rename(columns={\"index\": \"itemID\"}, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 153,
            "metadata": {},
            "outputs": [],
            "source": [
                "#applying tfidf to genres\n",
                "recommender=TfidfRecommender(id_col=\"itemID\",tokenization_method='bert')\n",
                "clean_movies=recommender.clean_dataframe(movies_df,cols_to_clean=[\"genre\"],new_col_name=\"genres\").drop(columns=[\"genre\"])\n",
                "tf, vectors_tokenized = recommender.tokenize_text(df_clean=clean_movies, text_col=\"genres\")\n",
                "recommender.fit(tf, vectors_tokenized)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = movielens.load_pandas_df(size=\"1m\", local_cache_path='./dataset/')\n",
                "\n",
                "train, validate, test = python_chrono_split(df, ratio=[0.8,0.1,0.1], filter_by=\"user\",col_user=\"userID\", col_item=\"itemID\", col_timestamp=\"timestamp\")\n",
                "userID_list = list(train['userID'].unique())\n",
                "\n",
                "#creat rating matrix\n",
                "r_matrix_train = train.pivot_table(index='userID', columns='itemID', values='rating')\n",
                "r_matrix_validate = validate.pivot_table(index='userID', columns='itemID', values='rating')\n",
                "r_matrix_test = test.pivot_table(index='userID', columns='itemID', values='rating')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 155,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Generate recommendations based on the k most similar items to the last item rated by the user,according to timestamp,movies_df,movies info\n",
                "def recommended_items(user_id, history, k):\n",
                "    target_item=int(history[history[\"userID\"] == user_id][\"itemID\"].iloc[-1])\n",
                "    sim_mov=[t[1] for t in(recommender.recommendations[target_item])][:k]\n",
                "    return sim_mov"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 156,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_similarity_matrix(similarity_dict):\n",
                "    # Find the total number of movies\n",
                "    num_movies = max(similarity_dict.keys())\n",
                "\n",
                "    # Initialize the similarity matrix with zeros\n",
                "    similarity_matrix = [[0.0] * num_movies for _ in range(num_movies)]\n",
                "\n",
                "    # Fill in the similarity values from the dictionary\n",
                "    for movie_id, similarities in similarity_dict.items():\n",
                "        for similarity in similarities:\n",
                "            other_movie_id = similarity[1]\n",
                "            similarity_value = similarity[0]\n",
                "            similarity_matrix[movie_id - 1][other_movie_id - 1] = similarity_value\n",
                "\n",
                "    return similarity_matrix\n",
                "\n",
                "def are_list_consecutive(input_list):\n",
                "    return input_list == list(range(min(input_list), max(input_list)+1))\n",
                "\n",
                "K = 20\n",
                "recommender.recommend_top_k_items(clean_movies, k=K)\n",
                "item_sim_mat = torch.tensor(create_similarity_matrix(recommender.recommendations), dtype=torch.float32)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 157,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/6040 [00:00<?, ?it/s]/tmp/ipykernel_9858/4201167791.py:9: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
                        "  for movie_id, rating in row.iteritems():\n",
                        "100%|██████████| 6040/6040 [01:29<00:00, 67.51it/s]\n"
                    ]
                }
            ],
            "source": [
                "def dataframe_to_tensor(df, total_num_of_users, total_num_of_movies):\n",
                "    # Initialize a tensor with zeros\n",
                "    user_movie_tensor = torch.zeros(total_num_of_users, total_num_of_movies)\n",
                "\n",
                "    # Iterate over DataFrame and fill in the tensor\n",
                "    with tqdm(total=len(df)) as pbar:\n",
                "        for index, row in df.iterrows():\n",
                "            user_id = index\n",
                "            for movie_id, rating in row.iteritems():\n",
                "                user_movie_tensor[user_id - 1, movie_id - 1] = rating\n",
                "            pbar.update()\n",
                "\n",
                "    return user_movie_tensor\n",
                "\n",
                "r_matrix_train_tensor = dataframe_to_tensor(r_matrix_train, len(userID_list), len(item_sim_mat))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 158,
            "metadata": {},
            "outputs": [],
            "source": [
                "r_matrix_predict = torch.matmul(r_matrix_train_tensor, item_sim_mat)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 159,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/6040 [00:00<?, ?it/s]/tmp/ipykernel_9858/4201167791.py:9: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
                        "  for movie_id, rating in row.iteritems():\n",
                        "100%|██████████| 6040/6040 [01:22<00:00, 73.41it/s]\n"
                    ]
                }
            ],
            "source": [
                "r_matrix_validate_tensor = dataframe_to_tensor(r_matrix_validate, len(userID_list), len(item_sim_mat))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 160,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Recall@20: 0.005936479667556973\n"
                    ]
                }
            ],
            "source": [
                "def recall_at_k(r_matrix_predict, r_matrix_validate_tensor, k):\n",
                "    # Get the number of users\n",
                "    num_users = r_matrix_predict.size(0)\n",
                "    \n",
                "    # Initialize recall sum\n",
                "    recall_sum = 0.0\n",
                "    \n",
                "    for user_idx in range(num_users):\n",
                "        # Sort predicted ratings for the user\n",
                "        predicted_ratings = r_matrix_predict[user_idx]\n",
                "        _, top_indices = torch.topk(predicted_ratings, k)\n",
                "        \n",
                "        # Get the set of movies in the top K for the user\n",
                "        top_movies_predicted = set(top_indices.numpy())\n",
                "        \n",
                "        # Get the set of actual rated movies for the user in the validation set\n",
                "        actual_movies_rated = set(torch.nonzero(r_matrix_validate_tensor[user_idx]).flatten().numpy())\n",
                "        \n",
                "        # Calculate the intersection of predicted and actual movies\n",
                "        intersection = top_movies_predicted.intersection(actual_movies_rated)\n",
                "        \n",
                "        # Calculate Recall@K for this user\n",
                "        recall_at_k_user = len(intersection) / len(actual_movies_rated) if len(actual_movies_rated) > 0 else 0.0\n",
                "        \n",
                "        # Add to recall sum\n",
                "        recall_sum += recall_at_k_user\n",
                "    \n",
                "    # Calculate average recall across all users\n",
                "    recall_at_k_avg = recall_sum / num_users\n",
                "    \n",
                "    return recall_at_k_avg\n",
                "\n",
                "k = 20  # Example value for k\n",
                "recall_at_20 = recall_at_k(r_matrix_predict, r_matrix_validate_tensor, k)\n",
                "print(\"Recall@20:\", recall_at_20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def actual_items(user_id, actual_rating_matrix):   \n",
                "    user_ratings = actual_rating_matrix.loc[user_id]\n",
                "    movies_rated = user_ratings.dropna().index.tolist()\n",
                "    return movies_rated\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def recall_at_k(user_id, train, k, evaluate_rating_matrix):\n",
                "    actual_items_list = actual_items(user_id, evaluate_rating_matrix)\n",
                "    recommended_items_list = recommended_items(user_id, train, k=k)\n",
                "    matched_item = set(actual_items_list).intersection(set(recommended_items_list))\n",
                "\n",
                "    recall = len(matched_item) / len(actual_items_list) if len(actual_items_list) > 0 else 0 \n",
                "    return recall\n",
                "\n",
                "def average_recall_at_k(userID_list, train, k, evaluate_rating_matrix=r_matrix_validate):\n",
                "    total_recall = 0\n",
                "    num_users = len(userID_list)\n",
                "    \n",
                "    with tqdm(total=len(userID_list)) as pbar:\n",
                "        for user_id in userID_list:\n",
                "            recall_at_k_value = recall_at_k(user_id, train, k, evaluate_rating_matrix)       \n",
                "            total_recall += recall_at_k_value\n",
                "            pbar.update(1)\n",
                "        \n",
                "    average_recall = total_recall / num_users if num_users > 0 else 0\n",
                "    return average_recall\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 6040/6040 [00:05<00:00, 1191.56it/s]\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0.015911516912690847"
                        ]
                    },
                    "execution_count": 76,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "recommender.recommend_top_k_items(clean_movies, 10)\n",
                "average_recall_at_k(userID_list, train, 10, r_matrix_validate)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
